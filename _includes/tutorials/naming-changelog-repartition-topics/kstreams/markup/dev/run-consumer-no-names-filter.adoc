////
  This is a sample content file for how to include a console consumer to the tutorial, probably a good idea so the end user can watch the results
  of the tutorial.  Change the text as needed.

////

If you haven't already stop the console-producer with a `CTRL+C` and re-start the console-consumer.  Remember the consumer is running with the `--from-beggining` option so you'll get all messages sent to the `output-topic` topic.


+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/console-consumer.sh %}</code></pre>
+++++

In this second run, you should see this output:

+++++
<pre class="snippet"><code class="shell">{% include_raw tutorials/naming-changelog-repartition-topics/kstreams/code/tutorial-steps/dev/expected-output-no-names-with-filter.txt %}</code></pre>
+++++

Even though the Kafka Streams application counts by key and you sent the same keys, the output is repeated.  Remember streams produced the first 3 records in the previous run.  So why is the output `1-1, 1-2, 1-3` instead of `1-4, 1-5, 1-6`?  Well you added a new operation to the topology, which incremented the counter used to generate the names of every processor, state store, and internal topic downstream of the new operator.

This renaming means the streams application `count()` processor now uses a new state store, vs. the one created when you first started the application.  The situation is the same if you used an in-memory store as the name of the changelog topic has changed as well, so there is nothing to restore once streams builds the in-memory store.

Your orginal data is still there, but it's just that streams isn't using the previously created state store and changelog topic.

You can close this consumer for now with a `CTRL+C`.
